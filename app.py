import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# ---- è¨­å®š ----
st.set_page_config(page_title="å°‚é–€å®¶ãƒãƒ£ãƒƒãƒˆ", page_icon="ğŸ§ ")

# ---- ã‚¢ãƒ—ãƒªã®èª¬æ˜ ----
st.title("ğŸ§  å°‚é–€å®¶ã¨è©±ãã†ï¼")
st.markdown("""
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€ã‚ãªãŸã®å…¥åŠ›å†…å®¹ã«å¯¾ã—ã¦2äººã®å°‚é–€å®¶ãŒå›ç­”ã—ã¦ãã‚Œã¾ã™ã€‚  
ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸ã³ã€å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦é€ä¿¡ã—ã¦ãã ã•ã„ã€‚
""")

# ---- å°‚é–€å®¶ã®é¸æŠ ----
expert = st.radio(
    "ä»¥ä¸‹ã®å°‚é–€å®¶ã‹ã‚‰é¸ã‚“ã§ãã ã•ã„ï¼š",
    ["å¥åº·ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼", "ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ"]
)

# ---- å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  ----
user_input = st.text_input("è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š")

# ---- å°‚é–€å®¶ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ----
def get_system_prompt(expert_choice):
    if expert_choice == "å¥åº·ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼":
        return "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªå¥åº·ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚å°‚é–€çš„ã§ã‚ã‚ŠãªãŒã‚‰ã€ã‚„ã•ã—ãåˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚"
    elif expert_choice == "ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ":
        return "ã‚ãªãŸã¯ä¸€æµã®ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚çµŒå–¶ã‚„ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã«ã¤ã„ã¦è«–ç†çš„ã«ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
    else:
        return "ã‚ãªãŸã¯åšè­˜ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"

# ---- å›ç­”ç”Ÿæˆé–¢æ•° ----
def generate_response(input_text, expert_choice):
    system_prompt = get_system_prompt(expert_choice)

    chat = ChatOpenAI(temperature=0.7, model_name="gpt-3.5-turbo")

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=input_text)
    ]

    response = chat(messages)
    return response.content

# ---- å›ç­”è¡¨ç¤º ----
if user_input:
    with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
        output = generate_response(user_input, expert)
        st.markdown("### å›ç­”ï¼š")
        st.write(output)
